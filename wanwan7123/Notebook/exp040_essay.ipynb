{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660744002033,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"79ca9ece-3c97-4664-de04-e87cd7d0e575"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Aug 17 13:46:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback-Exp040-essay-deberta-large\"\n","    MODEL_PATH = \"microsoft/deberta-large\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-effectiveness\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 4\n","    n_epochs = 5\n","    \n","    fc_dropout = 0.1\n","    weight_decay = 0.001\n","    beta = (0.9, 0.98)\n","    lr = 5e-6\n","    eval_steps = 499\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"fp16\": True,\n","        \"freezing\": True,\n","        \"optim8bit\": True,\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4709,"status":"ok","timestamp":1660744006738,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"6303a412-c31d-49da-833d-9a00f0c71d31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.10 in /usr/local/lib/python3.7/dist-packages (1.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import log_loss\n","!pip install torch==1.10\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    train['fold'] = fold_series\n","    return train, fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0EEPotHB-SJ"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -\u003e Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -\u003e Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -\u003e str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["def flatten(_list):\n","    return list(itertools.chain.from_iterable(_list))\n","\n","def even_split(input_ids):\n","    best_idx = None\n","    best_len = 100000\n","    for i in range(1, len(input_ids)):\n","        x_len = len(flatten(input_ids[:i]))\n","        y_len = len(flatten(input_ids[i:]))\n","        diff = abs(x_len - y_len)\n","        \n","        if best_len \u003e diff:\n","            best_len = diff\n","            best_idx = i\n","    \n","    return best_idx\n","\n","def preprocess_df(df, tokenizer, max_length=198, total_max_length:int=1024):\n","    df['discourse_text'] = df['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    df[\"input_text\"] = df[\"discourse_type\"] + \" \" + df[\"discourse_text\"]\n","\n","    # one-hot型の準備\n","    label_ar = df['label'].values\n","    onehot_ar = np.eye(3)[label_ar] \n","    df['Ineffective'] = onehot_ar[:, 0]\n","    df['Adequate'] = onehot_ar[:, 1]\n","    df['Effective'] = onehot_ar[:, 2]\n","    df['label_list'] = df[['Ineffective', 'Adequate', 'Effective']].values.tolist()\n","\n","\n","    gdf = df.groupby(\"essay_id\")\n","    fold_df = df.groupby('essay_id')['fold'].apply(lambda x: list(x)[0])\n","    \n","    essay_inputs = df.groupby(\"essay_id\")[\"input_text\"].apply(list)\n","    essay_ids = essay_inputs.index.tolist()\n","    \n","    labels = gdf[\"label_list\"].apply(list)\n","    discourse_ids = gdf[\"discourse_id\"].apply(list)\n","    \n","    rows = []\n","    for i in tqdm(range(len(essay_inputs))):\n","        # まず全体をtokenizeして1024に収まっていれば、各テキストをtruncationしておく必要はない\n","        input_ids = tokenizer.batch_encode_plus(essay_inputs[i], max_length=total_max_length, truncation=True)[\"input_ids\"]\n","        \n","        if len(flatten(input_ids)) \u003e total_max_length:\n","            split_idx = even_split(input_ids)\n","            \n","            first = input_ids[:split_idx]\n","            first_seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(first)]\n","\n","            second = input_ids[split_idx:]\n","            second_seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(second)]\n","            essay_id = essay_ids[i]\n","            \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":1,\n","                \"discourse_id\": discourse_ids[i][:split_idx ],\n","                \"label\":labels[i][:split_idx],\n","                \"input_ids\":flatten(first),\n","                \"seq_ids\":flatten(first_seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","        \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":2,\n","                \"discourse_id\": discourse_ids[i][split_idx:],\n","                \"label\":labels[i][split_idx:],\n","                \"input_ids\":flatten(second),\n","                \"seq_ids\":flatten(second_seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","        else:\n","            # もしかしたら一つのtextで1024超える場合もある？\n","            seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(input_ids)]\n","            input_ids = flatten(input_ids)\n","            essay_id = essay_ids[i]\n","            \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":1,\n","                \"discourse_id\": discourse_ids[i],\n","                \"label\":labels[i],\n","                \"input_ids\":input_ids,\n","                \"seq_ids\":flatten(seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","            \n","    return pd.DataFrame(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53jHZmig2OH2"},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer):\n","        super().__init__()\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        \n","        inputs = {}\n","        \n","        input_ids = np.array(row[\"input_ids\"])\n","        seq_ids = np.array(row[\"seq_ids\"])\n","        label = np.array(row['label'])\n","        \n","        attention_mask = np.array([1 if id != self.tokenizer.pad_token_id else 0 for id in input_ids], dtype=np.int64)\n","        \n","        inputs = {\n","            \"discourse_id\":row[\"discourse_id\"],\n","            \"input_ids\":input_ids,\n","            \"attention_mask\":attention_mask,\n","            \"seq_ids\":seq_ids,\n","            \"label\":label,\n","        }\n","        \n","        return inputs\n","\n","# バッチごとにパディング操作を行う\n","class Collator:\n","    def __init__(self, tokenizer, input_cols, meta_cols=None):\n","        self.tokenizer = tokenizer\n","        self.input_cols = input_cols\n","        \n","        self.meta_cols = meta_cols if meta_cols is not None else []\n","        \n","        self.padding = True\n","        self.max_length: Optional[int] = None\n","        self.pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        first = features[0]\n","        \n","        input_features = []\n","        meta_features = {meta_col:[] for meta_col in self.meta_cols}\n","        \n","        for f in features:\n","            input_features.append({col:f[col] for col in self.input_cols})\n","            for meta_col in self.meta_cols:\n","                meta_features[meta_col].extend(f[meta_col])\n","            \n","        batch = self.tokenizer.pad(\n","            input_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","        \n","        if \"label\" in first:\n","            batch[\"labels\"] = pad_sequence([torch.tensor(f[\"label\"], dtype=torch.float) for f in features], batch_first=True, padding_value=-1)\n","\n","        if \"seq_ids\" in first:\n","            batch[\"seq_ids\"] = pad_sequence([torch.tensor(f[\"seq_ids\"], dtype=torch.long) for f in features], batch_first=True, padding_value=-1)\n","            \n","        if self.meta_cols is not None:\n","            batch[\"meta\"] = meta_features\n","\n","        \n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDh1Mz2G2Cnm"},"outputs":[],"source":["class SimpleHeader(nn.Module):\n","    def __init__(self, input_size:int, num_labels):\n","        super().__init__()\n","        self.fc = nn.Linear(input_size, num_labels)\n","\n","        self.cls_dropouts = nn.Sequential(\n","            nn.Dropout(0.1),\n","            nn.Dropout(0.2),\n","            nn.Dropout(0.3),\n","            nn.Dropout(0.4),\n","            nn.Dropout(0.5),\n","        )\n","\n","    def forward(self, x):\n","        output = torch.mean(\n","            torch.stack(\n","                [self.fc(self.cls_dropouts[i](x)) for i in range(5)],\n","                dim=0,\n","            ),\n","            dim=0,\n","        )\n","        return output\n","\n","class LitModel(nn.Module):\n","    def __init__(self,cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": 0.1,\n","                \"layer_norm_eps\": 1e-7,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": 3,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )   \n","        self.hidden_size = self.config.hidden_size\n","        self.fc = nn.Linear(self.config.hidden_size, 3)\n","        self.header = SimpleHeader(input_size=self.config.hidden_size, num_labels=3)\n","        self._init_weights(self.header.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=0)\n","        )\n","        self._init_weights(self.attention)\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()\n","\n","    @property\n","    def device(self):\n","        return self.backbone.device\n","            \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, last_hidden_state):\n","        weights = self.attention(last_hidden_state)\n","        feature = torch.sum(weights * last_hidden_state, dim=0)\n","        return feature\n","\n","    # トークンごとに平均取って潰す\n","    def sequence_mean(self, logits, batch):\n","        batch_seq_mean = []\n","        batch_size = batch[\"input_ids\"].shape[0]\n","        seq_lens = []\n","        # バッチサイズごとに\n","        for i in range(batch_size):\n","            seq_mean = []\n","            # バッチの長さに応じて処理\n","            # iはバッチを表すので、そのバッチで何個文章がくっついてるかをjは表す\n","            for j in range(max(batch[\"seq_ids\"][i])+1):\n","                # i, j成分（該当するdiscourse）を取り出す\n","                idx = batch[\"seq_ids\"][i]==j\n","                idx = idx.nonzero().reshape(-1)\n","                # idxでtensorの抜き出しを行う\n","                seq_tensor = torch.index_select(logits[i], 0, idx)\n","                seq_tensor = self.feature(seq_tensor)\n","                seq_mean.append(seq_tensor)\n","\n","            seq_lens.append(len(seq_mean))\n","            batch_seq_mean.append(torch.vstack(seq_mean))\n","\n","        return batch_seq_mean, seq_lens\n","            \n","    def forward(self, input_dict, labels):\n","        # batch, len, hidden_size\n","        output = self.backbone(\n","            input_ids=input_dict[\"input_ids\"],\n","            attention_mask=input_dict[\"attention_mask\"]\n","        )[\"last_hidden_state\"]\n","    \n","        # discourse, hidden_size\n","        output, seq_lens = self.sequence_mean(output, input_dict)\n","        # discourse, hidden_size\n","        output = torch.vstack(output)\n","        output = self.header(output)\n","\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(output, labels)\n","            return loss, output\n","        else:\n","            return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6wGuA-o0eL8"},"outputs":[],"source":["# FGM\n","# https://www.kaggle.com/competitions/tweet-sentiment-extraction/discussion/143764#809408\n","\n","class FGM():\n","    def __init__(self, model):\n","        self.model = model\n","        self.backup = {}\n","\n","    def attack(self, epsilon=1.0, emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                self.backup[name] = param.data.clone()\n","                norm = torch.norm(param.grad)\n","                if norm != 0:\n","                    r_at = epsilon * param.grad / norm\n","                    param.data.add_(r_at)\n","\n","    def restore(self, emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                assert name in self.backup\n","                param.data = self.backup[name]\n","            self.backup = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_all_df = pd.DataFrame()\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[train['fold']!=fold]\n","        valid_df = train.loc[train['fold']==fold]\n","\n","        # psuedo_dataの追加\n","        psuedo_df = pd.read_csv(f'/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback/wanwan7123/Input/exp020/ver1/psuedo_fold{fold}_sample.csv')\n","        psuedo_df['discourse_id'] = psuedo_df['discourse_id'].apply(lambda x: eval(str(x)))\n","        psuedo_df['label'] = psuedo_df['label'].apply(lambda x: eval(str(x)))\n","        psuedo_df['input_ids'] = psuedo_df['input_ids'].apply(lambda x: eval(str(x)))\n","        psuedo_df['seq_ids'] = psuedo_df['seq_ids'].apply(lambda x: eval(str(x)))\n","        train_df = pd.concat([train_df, psuedo_df]).reset_index(drop=True)\n","\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(train_df, cfg.tokenizer)\n","        valid_dataset = TrainDataset(valid_df, cfg.tokenizer)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collator(cfg.tokenizer, input_cols = [\"input_ids\", \"attention_mask\"], meta_cols = [\"discourse_id\"])\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collator(cfg.tokenizer, input_cols = [\"input_ids\", \"attention_mask\"], meta_cols = [\"discourse_id\"])\n","        )\n","\n","        # model\n","        model = LitModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {\n","                'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                'weight_decay': cfg.weight_decay\n","            },\n","            {\n","                'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                'weight_decay': 0.0\n","            }\n","        ]\n","\n","        # optimizer\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        \n","        # scaler\n","        scaler = GradScaler()\n","\n","        # enable FGM\n","        fgm = FGM(model)\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.CrossEntropyLoss()\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            val_losses_batch = []\n","            ids = []\n","            # dataloader回して予測\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs) in enumerate(pbar):\n","\n","                    meta = inputs.pop(\"meta\", None)\n","                    inputs = {k:v.to(cfg.device) for k, v in inputs.items()}\n","                    labels = inputs['labels'][torch.where(inputs['labels'] != -1)].reshape(-1, 3)\n","                    optimizer.zero_grad()\n","\n","                    with autocast():\n","                        loss, output = model(inputs, labels)\n","                    \n","                    ids.extend(meta[\"discourse_id\"])\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","\n","                    # FGM attack\n","                    fgm.attack()\n","                    with autocast():\n","                        loss_adv, _ = model(inputs, labels)\n","                    scaler.scale(loss_adv).backward()\n","                    fgm.restore()\n","                    \n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    # evaluating\n","                    if ((step+1) % cfg.eval_steps == 0):\n","                        print('===========steps：', step, '==========')\n","                        val_preds = []\n","                        val_losses = []\n","                        val_nums = []\n","                        ids = []\n","                        model.eval()\n","                        with torch.no_grad():\n","                            with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","                                for steps, (inputs) in enumerate(pbar):\n","\n","                                    meta = inputs.pop(\"meta\", None)\n","                                    inputs = {k:v.to(cfg.device) for k, v in inputs.items()}\n","                                    labels = inputs['labels'][torch.where(inputs['labels'] != -1)].reshape(-1, 3)\n","\n","                                    with autocast():\n","                                        loss, output = model(inputs, labels)\n","                                    ids.extend(meta[\"discourse_id\"])\n","\n","                                    output = output.detach().cpu().numpy()\n","                                    val_preds.append(output)\n","                                    val_losses.append(loss.item() * len(labels))\n","                                    val_nums.append(len(labels))\n","                                    pbar.set_postfix({\n","                                        'val_loss': loss.item()\n","                                    })\n","\n","                        val_preds = np.vstack(val_preds)\n","                        val_loss = sum(val_losses) / sum(val_nums)\n","\n","                        val_log = {\n","                            'val_loss': val_loss\n","                        }\n","                        display(val_log)\n","\n","                        if best_val_score \u003e val_loss:\n","                            print(\"save model weight\")\n","                            best_val_preds = val_preds\n","                            best_val_score = val_loss\n","                            torch.save(\n","                                model.state_dict(), \n","                                os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","                            )\n","                        \n","                        model.train()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating(per epoch)\n","            print(' ==========end epoch ==========')\n","            val_preds = []\n","            val_losses = []\n","            val_nums = []\n","            ids = []\n","            model.eval()\n","            with torch.no_grad():\n","                with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","                    for steps, (inputs) in enumerate(pbar):\n","\n","                        meta = inputs.pop(\"meta\", None)\n","                        inputs = {k:v.to(cfg.device) for k, v in inputs.items()}\n","                        labels = inputs['labels'][torch.where(inputs['labels'] != -1)].reshape(-1, 3)\n","\n","                        with autocast():\n","                            loss, output = model(inputs, labels)\n","                        ids.extend(meta[\"discourse_id\"])\n","\n","                        output = output.detach().cpu().numpy()\n","                        val_preds.append(output)\n","                        val_losses.append(loss.item() * len(labels))\n","                        val_nums.append(len(labels))\n","                        pbar.set_postfix({\n","                            'val_loss': loss.item()\n","                        })\n","\n","            val_preds = np.vstack(val_preds)\n","            val_loss = sum(val_losses) / sum(val_nums)\n","\n","            val_log = {\n","                'val_loss': val_loss\n","            }\n","            display(val_log)\n","\n","            if best_val_score \u003e val_loss:\n","                print(\"save model weight\")\n","                best_val_preds = val_preds\n","                best_val_score = val_loss\n","                torch.save(\n","                    model.state_dict(), \n","                    os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","                )\n","\n","        oof_df = pd.DataFrame(ids, columns=['discourse_id'])\n","        oof_df['Ineffective'] = best_val_preds[:, 0]\n","        oof_df['Adequate'] = best_val_preds[:, 1]\n","        oof_df['Effective'] = best_val_preds[:, 2]\n","        oof_df.to_csv(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.csv'))\n","        oof_all_df = pd.concat([oof_all_df, oof_df], axis=0)\n","        del model; gc.collect()\n","\n","    oof_all_df.to_csv(os.path.join(cfg.EXP_PREDS, 'oof_pred.csv'))\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    '''\n","    metric = nn.CrossEntropyLoss()\n","    score = metric(torch.from_numpy(oof_pred), torch.from_numpy(train['label'].values))\n","    print('CV:', score.to('cpu').detach().numpy())\n","    '''\n","    return oof_all_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.53)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.8.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.11.6 in /usr/local/lib/python3.7/dist-packages (0.11.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.8.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,\u003e=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f16d30dfa8c47049d31c260e47cc37f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4191 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-3d9d0af0-38fe-454f-8dad-ebc3d315f28d\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eessay_id\u003c/th\u003e\n","      \u003cth\u003egroup\u003c/th\u003e\n","      \u003cth\u003ediscourse_id\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003einput_ids\u003c/th\u003e\n","      \u003cth\u003eseq_ids\u003c/th\u003e\n","      \u003cth\u003efold\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e00066EA9880D\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[fe6dfbd53216, ca9e1b60c9fb, 6cf2157f4f19, d92...\u003c/td\u003e\n","      \u003ctd\u003e[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...\u003c/td\u003e\n","      \u003ctd\u003e[1, 32258, 16870, 1672, 1677, 32, 1931, 40054,...\u003c/td\u003e\n","      \u003ctd\u003e[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e000E6DE9E817\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[695d181861a1, cd97ee1cc0ad, 1b775274990b, 567...\u003c/td\u003e\n","      \u003ctd\u003e[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...\u003c/td\u003e\n","      \u003ctd\u003e[1, 46884, 38, 524, 7594, 136, 5, 714, 464, 14...\u003c/td\u003e\n","      \u003ctd\u003e[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0016926B079C\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[89304284cef1, 4f2e871a4908, a885c3aa214b, 953...\u003c/td\u003e\n","      \u003ctd\u003e[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...\u003c/td\u003e\n","      \u003ctd\u003e[1, 46884, 38, 206, 14, 521, 74, 1796, 31, 223...\u003c/td\u003e\n","      \u003ctd\u003e[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e00203C45FC55\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[a713d0f6dc68, 2fd9bb2bfedf, 0e5ecdf1516e, 499...\u003c/td\u003e\n","      \u003ctd\u003e[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...\u003c/td\u003e\n","      \u003ctd\u003e[1, 32258, 85, 16, 358, 1294, 18, 3366, 7, 28,...\u003c/td\u003e\n","      \u003ctd\u003e[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e0029F4D19C3F\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[1082de1aa198, e425994b2124, bf086f9911f6, 29c...\u003c/td\u003e\n","      \u003ctd\u003e[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...\u003c/td\u003e\n","      \u003ctd\u003e[1, 32258, 38, 1317, 47, 32, 2811, 2992, 5, 13...\u003c/td\u003e\n","      \u003ctd\u003e[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d9d0af0-38fe-454f-8dad-ebc3d315f28d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-3d9d0af0-38fe-454f-8dad-ebc3d315f28d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3d9d0af0-38fe-454f-8dad-ebc3d315f28d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["       essay_id  group                                       discourse_id  \\\n","0  00066EA9880D      1  [fe6dfbd53216, ca9e1b60c9fb, 6cf2157f4f19, d92...   \n","1  000E6DE9E817      1  [695d181861a1, cd97ee1cc0ad, 1b775274990b, 567...   \n","2  0016926B079C      1  [89304284cef1, 4f2e871a4908, a885c3aa214b, 953...   \n","3  00203C45FC55      1  [a713d0f6dc68, 2fd9bb2bfedf, 0e5ecdf1516e, 499...   \n","4  0029F4D19C3F      1  [1082de1aa198, e425994b2124, bf086f9911f6, 29c...   \n","\n","                                               label  \\\n","0  [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n","1  [[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...   \n","2  [[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...   \n","3  [[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n","4  [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...   \n","\n","                                           input_ids  \\\n","0  [1, 32258, 16870, 1672, 1677, 32, 1931, 40054,...   \n","1  [1, 46884, 38, 524, 7594, 136, 5, 714, 464, 14...   \n","2  [1, 46884, 38, 206, 14, 521, 74, 1796, 31, 223...   \n","3  [1, 32258, 85, 16, 358, 1294, 18, 3366, 7, 28,...   \n","4  [1, 32258, 38, 1317, 47, 32, 2811, 2992, 5, 13...   \n","\n","                                             seq_ids  fold  \n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     2  \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...     0  \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...     1  \n","3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     1  \n","4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     2  "]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4f94694d6f44d83961f5ec2316811dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1003 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c6f2b6ff12e44559436294715d7d029","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6864671661828463}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cca672b4ae74b7ca7b25a8ac8c8a24a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6510388285116316}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.7530382654041575}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49f7ccae078940ebb1615596a6cd6def","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6644355647283609}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70385e2f0b1047b591c6e9486a40b919","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1003 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3d88781753f4d32911c3b978d4b5923","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6795870781153259}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a31a097e783341cf9731faa480205900","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6254852683976289}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.636278331876848}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc7b65320258410f88ffafec73415ac2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6222564826369694}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a95b6b83af884cc693f8a29829f9d9f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1003 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8065777485a94a97808d4f29240422e6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6260191564143145}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ae42d1bfeeb4747844f5a2d9677edf6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.599860544166289}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.5749863856180083}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc4d952ad29846848263dda57894b8f1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5960439973967737}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a530c0aea9f04072a1c9ab31b6317372","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1003 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04c4ea72e6c94890b91a570a1cc18543","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6022388810018069}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1555495196ec4c94bbfbc972f39550c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6215532991600583}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5218405961177573}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fc7fab7e35d4515bde98d1058eae0fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6127799874583078}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b99c62e47a64cb48806b03e6b063f5e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1003 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c120dc7abe248a1b189a38456c6b610","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6087391504869907}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aca192ca8bdf4fbe831ebe1bd0112c28","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6079887018044223}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4945912766472572}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a9cb59440dc4b289f57515f2fedc2f6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6080001821688862}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faf94b19d13e46cfbe4905f9ffeb041b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/982 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d943f575dfe410e90a664311acc8f09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6999966980158373}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.7326346556290618}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3308cd4037a14eab9d6d9e149d2d9e76","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6774674642281185}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dddedd1d4ea41608b781809d5f57247","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/982 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3bdb63156da487797522f57dce96830","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6715332885435644}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.6146263624884486}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbfdd228ab124208b25edce6d3e0802c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6518981191737728}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2a18a2a04ce41159300bb8eabb32485","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/982 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bf6792b8604463a94b4b102302d1779","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.647339644684131}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.5511201679697608}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f661bb88a1cf47cf895c6267363397ea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6587402534904695}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06446848aa2240bd8427c33abcb39d17","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/982 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b1780404e9c4936a84a96079308ec8b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6596626402923732}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.49710271544319506}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd20f8533e134bf899bc8f64757ba467","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.663664983151654}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"101df6f40318483a8c87d22f091101c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/982 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50105a273c7b4cfe8adb482d399ab672","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6631582838122234}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4658374917960385}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da213ce3bc6746c1a8339e1fc8c4f774","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/218 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6594908168127619}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a48f273510cb4b7ea43a826a04091511","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/978 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"592b3dca5810444499496b66d7926ce0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.700541705766018}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.7473711998756151}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"516d6b56f3ae492794a48caf068863e6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6314436858095297}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc48bf6f33894597ad44351255088ac3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/978 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1df09f7b2ae4802974ad9b94730e323","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6313658041349924}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.6286693839612759}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1cd0f1ae9fd4bd58169d81bf412a015","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5996298683211764}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b46d637f18e94da3985ec5bd9b8e3b7f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/978 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c45270b1cfa428687228d02e10d1a0a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5972224786634701}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.5641137088880552}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"887b8bd5066d46ddbe6e11bd75695ec4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5876228047293436}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"117a6d9be82542cfb18555eb95a892b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/978 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f99449da7484347be862d9c9b193623","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5976044636535757}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5117096274175023}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fa85235adaf47f0ada3c58ec336b1b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5997853604682937}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"608951f83c504877a302037aa9810a38","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/978 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35efe37967494ec691bf4b33ed525586","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5979517839167552}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.48498415327824207}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4f92b23adf847078900ab0c1812c72a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5987519874044728}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7aa44ab38e20439ea8eb49754f3c863e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/973 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f48feea16d24668848cf41f78ca1c0a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6910013075823782}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.7497073641506473}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b28ad2a184164bc7ab9a3f8f8883da43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.7045669836725305}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"953cfbaef5854694b17d54663ff738f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/973 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3f06faa1878471e9ef3c13babdede8e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6428011819827036}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.6302662336382188}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79bda5274dc84fc5916765cfee6dab6b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6332560100796514}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b070dff3b2c842329176e9ef183a3a7b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/973 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b50080441d44b5c9ddb3a7ffab54a49","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6295318062142358}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.569590147092846}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eedf1038cdd64d878c77b232fa6a0e4e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6191941588669834}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa3b518ff57049ba86b33576ec6397c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/973 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23f216b690ee477ab996d6131cef3a13","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6193433932046464}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5179487540051121}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3be5a54ba93c4b278550807d9ecfa753","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6085327548143975}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1c34c2118db41b9920fcc5a545dc2a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/973 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c95ab55c182640e1849d10231d483833","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6144818013884722}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.48788768019667184}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bf11b3bf5984d2993ad152f0073c585","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6162232505448432}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aba82c9c8db44842a80b827e44d5cb6e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1008 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7137577743346819f1724d7b5c08e8a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.7006727786905799}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b76df3d43d436f94fc4c4bd9682816","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.7275953200816715}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7355982641753736}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df5712e896d34abf968e4c3c53f303e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6656129790599671}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11bd6c5bd9c24197bfaf46753ce928d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1008 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2002b234a7a4f78a32b655f8b80e31c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6348217479249335}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b3260e9361d4e1b867f7d660b6134ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.619811552804724}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.6236221879788452}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da0e76c471e04594a3d63b8714b4ed01","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6320827033851036}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"012fb3939bf848cca6caa8873f41026c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1008 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eac4ebcc74941b1a9284c8ec14371d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6083405967410508}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4802e6f90554578aa9157cbf0d27668","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6085583927718784}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.558928007005637}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c3a5426eed44dd58cb7eea41b752630","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6305689754622594}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d08ce0541c54019a046dafe1c455b8a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1008 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22eae542642f469bae4d4947b778ad7b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6042514283235103}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb8cf156b65147f3b47c6f222bff5779","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6028729428404327}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.5091628715479767}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46d50e55ad5d4cb587371ff374ce0025","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.607927998453972}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3631bb1309ef439799a78c30dddff0bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1008 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 498 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e87f7ced013648658e31833daaf65c11","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6077250041109543}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===========steps： 997 ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57cfb053793540a2939e3fc4e6bd747c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6064364814658455}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.48113202516028314}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" ==========end epoch ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce62dbd57c704db1a6ba04adc62ade15","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6064371622420595}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7.56G/7.56G [03:41\u003c00:00, 36.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (8GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:03\u003c00:00, 2.67kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.90M/2.90M [00:02\u003c00:00, 1.06MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (3MB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3.22M/3.22M [00:02\u003c00:00, 1.34MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (3MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36k/2.36k [00:02\u003c00:00, 904B/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (2KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_cosine_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_full.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","train['label'] = train['discourse_effectiveness'].map({'Ineffective':0, 'Adequate':1, 'Effective':2})\n","train['type_label'] = train['discourse_type'] + '_' + train['discourse_effectiveness']\n","train, cfg.folds = get_groupstratifiedkfold(train, 'type_label', 'essay_id', cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","\n","train = preprocess_df(train, cfg.tokenizer, max_length=198, total_max_length=1024)\n","display(train.head())\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOWzVQLzWY+xfiPdy8vNCWE","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","name":"exp040_essay.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}