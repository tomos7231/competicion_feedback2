{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1656777484673,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"40f6c0a3-f664-4811-b427-675df943be0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Jul  2 15:58:04 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback-Exp003-deberta-v3-large\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-effectiveness\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/feedback-prize\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 12\n","    n_epochs = 3\n","    max_len = 512\n","    \n","    fc_dropout = 0.1\n","    weight_decay = 0.001\n","    beta = (0.9, 0.98)\n","    lr = 4e-6\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"fp16\": True,\n","        \"freezing\": True,\n","        \"optim8bit\": True,\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95040,"status":"ok","timestamp":1656777607356,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"b28def54-2eec-4663-e0b5-3349b01f5742"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.9.1\n","  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 5.8 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (4.1.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.1\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import log_loss\n","\n","! pip install torch==1.9.1\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collate:\n","    def __init__(self, tokenizer, return_label=False):\n","        self.tokenizer = tokenizer\n","        self.return_label = return_label\n","\n","    def __call__(self, batch):\n","        labels =  [label for _, label in batch]\n","        batch = [_batch for _batch, _ in batch]\n","\n","        output = dict()\n","\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(token_id) for token_id in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","\n","        if self.return_label:\n","            labels = torch.tensor([sample for sample in labels], dtype=torch.long)\n","\n","        return output, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3692,"status":"ok","timestamp":1656777626530,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"oPz3nkpUvn9s","outputId":"335b79b9-f77d-4020-dee1-4de690a8802f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\r\u001b[K     |                                | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |▏                               | 20 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |▎                               | 30 kB 46.0 MB/s eta 0:00:01\r\u001b[K     |▍                               | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 51 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 61 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 71 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 81 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 92 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 102 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 112 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 122 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 133 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 143 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 153 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 163 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 174 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 184 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 194 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 204 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 215 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 225 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 235 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 245 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 256 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 266 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 276 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 286 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 296 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 307 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 317 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 327 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 337 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 348 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 358 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 368 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 378 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 389 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 399 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 409 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 419 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 430 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 440 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 450 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 460 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 471 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 481 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 491 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 501 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 512 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 522 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 532 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 542 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 552 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 563 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 573 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 583 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 593 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 604 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 614 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 624 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 634 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 645 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 655 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 665 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 675 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 686 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 696 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 706 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 716 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 727 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 737 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 747 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 757 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 768 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 778 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 788 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 798 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 808 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 819 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 829 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 839 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 849 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 860 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 870 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 880 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 890 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 901 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 911 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 921 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 931 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 942 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 952 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 962 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 972 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 983 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 993 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.4 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.5 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.6 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.7 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.8 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.9 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.1 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.2 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3 MB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3 MB 15.7 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q bitsandbytes-cuda110"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZabItR15TO6B"},"outputs":[],"source":["# 勾配計算をしない\n","import bitsandbytes as bnb\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","def get_essay(essay_id, train=True):\n","    essay_path = os.path.join(cfg.INPUT, f\"train/{essay_id}.txt\")\n","    essay_text = open(essay_path, 'r').read()\n","    return essay_text\n","\n","def processing_features(df, train=True):\n","    # ラベルに変換\n","    df['label'] = df['discourse_effectiveness'].map({'Ineffective':0, 'Adequate':1, 'Effective':2})\n","    # 1つになってるtextを持ってくる。今回は前処理済み\n","    # df['full_text'] = df['essay_id'].apply(get_essay, train=True)\n","    df['text'] = df['discourse_type'] + '[SEP]' + df['discourse_text'] + '[SEP]' + df['full_text']\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.text = df['text'].to_numpy()\n","        self.labels = df['label'].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.text[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.long)\n","        return inputs, self.labels[index]\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text,\n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        return inputs\n","\n","# バッチ単位でcollatteをする\n","def collatte(inputs, labels=None):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    if not labels is None:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        labels =  labels[:,:mask_len]\n","        return inputs, labels, mask_len\n","                \n","    else:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        return inputs, mask_len\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": 0.1,\n","                \"layer_norm_eps\": 1e-7,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": 3,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc = nn.Linear(self.config.hidden_size, 3)\n","        self._init_weights(self.fc)\n","        self.dropout = nn.Dropout(cfg.fc_dropout)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","        # Freeze\n","        if self.gpu_optimize_config['freezing']:\n","            freeze(self.backbone.embeddings)\n","            freeze(self.backbone.encoder.layer[:2])\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()  \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, inputs):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_state = outputs[0]\n","        out = self.layer_norm1(last_hidden_state[:, 0, :])\n","        logits1 = self.fc(self.dropout1(out))\n","        logits2 = self.fc(self.dropout2(out))\n","        logits3 = self.fc(self.dropout3(out))\n","        logits4 = self.fc(self.dropout4(out))\n","        logits5 = self.fc(self.dropout5(out))\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros((len(train), 3), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {\n","                'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                'weight_decay': cfg.weight_decay\n","            },\n","            {\n","                'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                'weight_decay': 0.0\n","            }\n","        ]\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        \n","        if cfg.gpu_optimize_config['gradient_checkpoint']:\n","            optimizer = bnb.optim.AdamW(optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","            optim_bits=8)\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.CrossEntropyLoss()\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            val_losses_batch = []\n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        output = model(inputs)\n","                    loss = criterion(output, labels)\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating\n","            val_preds = []\n","            val_losses = []\n","            val_nums = []\n","            model.eval()\n","            with torch.no_grad():\n","                with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","                    for (inputs, labels) in pbar:\n","                        for k, v in inputs.items():\n","                            inputs[k] = v.to(cfg.device)\n","                        labels = labels.to(cfg.device)\n","                        with autocast():\n","                            output = model(inputs)\n","                        loss = criterion(output, labels.to(torch.long))\n","                        \n","                        output = output.detach().cpu().numpy()\n","                        val_preds.append(output)\n","                        val_losses.append(loss.item() * len(labels))\n","                        val_nums.append(len(labels))\n","                        pbar.set_postfix({\n","                            'val_loss': loss.item()\n","                        })\n","\n","            val_preds = np.concatenate(val_preds)\n","            val_loss = sum(val_losses) / sum(val_nums)\n","\n","            val_log = {\n","                'val_loss': val_loss\n","            }\n","            display(val_log)\n","\n","            if best_val_score \u003e val_loss:\n","                print(\"save model weight\")\n","                best_val_preds = val_preds\n","                best_val_score = val_loss\n","                torch.save(\n","                    model.state_dict(), \n","                    os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","                )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    metric = nn.CrossEntropyLoss()\n","    score = metric(torch.from_numpy(oof_pred), torch.from_numpy(train['label'].values))\n","    print('CV:', round(score, 5))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 15.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 78.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,\u003e=0.10.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 66.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.7.1)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.4)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 79.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=86a209b3a8a8ed7fbfce84da6914074a7c61623fe249b2bf1fa4e64fef690c54\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.16.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.11.6\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 15.6 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","Successfully installed tokenizers-0.11.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.4)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.8.1)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Collecting sentencepiece!=0.1.92,\u003e=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 13.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07d6f32d8b6d4a70aca231e0b3af87b6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80e64b78c23b499abf76a91d62633804","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2848e872d76047fb9cbebf16603499dc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e85cbc98fb8d4ecdbd1dd234a0a0ab6f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fa41843589746fe9bc2f916b3a2587b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1842 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7323705816113599}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"311d471789974127800efe0c921feffa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/456 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6786306858651998}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb4c9e45a81c4174914f04ddf274cf96","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1842 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5675887150303678}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff01864569284b7dbd8d29be95da4bd9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/456 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6555418145209735}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b8d8f0cff1241a4ba5cd01c8f30456f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1842 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.48863738781725025}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e5b9c0af7b24a499cc868df2694b99a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/456 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.673768724040574}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c839de5cd349464aa364e8e90d9b2887","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1855 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7099910108869609}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcb00f51db244152a85cc8ae7362a028","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/443 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6514778002602328}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b29997fa88314c09a714fa834a9cfe99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1855 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5684117566543126}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2d5d7f1e8df44baa5e14da07c246930","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/443 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6456880320439309}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e58785d5dee6450ba715f82e85e87193","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1855 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4899485133086253}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4763f72c05fd4d26bae57e83884760b3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/443 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6787955683221595}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08602abc85704d68891e9d271c1aeddf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1841 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7036661938569392}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"658233f16caa47d8b152b286b5d34000","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/457 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6724685915661825}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87b90ab2a5544385a40862dcdc51a7e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1841 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.568740438599097}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5653b3a2837e438391b173d544e18aff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/457 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6431149801315429}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8ff5b39868d4cb1afb8cf542599d618","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1841 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4921022298088675}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53cf383c3f8f447abd89bc2c2d62ee5e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/457 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6727570909838312}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2eeb9e2e913e40a2b404911f252fc2f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1827 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7324171979765326}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cb5de03445b403f9bb2e2aec907e4d1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/471 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6235412581427812}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b2e52b40e1a42dabb07afae0d27ddb3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1827 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5739703332392584}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd83928168284a8481580f9027d844c3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/471 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6210915429323983}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdb7643f3a2c475e97e351b7a9863eca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1827 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4917996411253079}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60502b4df6b9421c98aae95fa498cbe9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/471 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6468488008092927}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec169a53dac14b3ca2b3dc2fde291667","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1824 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7128740277206689}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b1ccece69644a33bfaa410ce32feb73","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/474 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6555147748737957}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eaa0c2db9614f05aa9bfc888c1170cf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1824 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5590644301029674}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"944ca0392e58481b9b27420870007550","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/474 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6656566477394582}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9a3c44657144cc6a8418d42c18fa453","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1824 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.47510250827722383}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eda3de3ddb04c7d8c71b1cc1be49763","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/474 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.7004254690902567}"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-12-c149ec053f1c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_groupstratifiedkfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'essay_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXP_PREDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'folds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 28\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_from_colab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-11-67e05593a535\u003e\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(cfg, train)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 175\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: type Tensor doesn't define __round__ method"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_full.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train, train=True)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_groupstratifiedkfold(train, 'label', 'essay_id', cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwTIVNWuwErN"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPq9yGzEwbOD8UJytEVDK7t","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","name":"exp003.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"004bda8732f348b59e58e5755c153c2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05098bd3c8e148aea403a30221888f0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07d6f32d8b6d4a70aca231e0b3af87b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2328e991c05e4c8aa191bade92839d8b","IPY_MODEL_c6cbe18f52264f37a914c7abf3e923f5","IPY_MODEL_7b0abfd07a0c42cfacbb6f5adacdf201"],"layout":"IPY_MODEL_f783643d9ee3492baa3dd45e577fd19b"}},"0dfd43845ba84b759deba6c1f12e13c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"125b4cee2b744e95abbb42e4a628b417":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"127deb6965054d3eaf250db46354a9d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aec48847b5f4aa7aadc2f098567efc0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bfc703f02e043cea80313d15c76574e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fa41843589746fe9bc2f916b3a2587b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97a1fedd86234c77a50666903b5aa6dd","IPY_MODEL_e482a79f9f7a45e8a7e0f38e298da840","IPY_MODEL_c8d085e76d3d4db289f45439f71b5940"],"layout":"IPY_MODEL_6a8fab6d6b0d4b73a78e564db1a839c7"}},"2328e991c05e4c8aa191bade92839d8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_861808a2dbed4b78babb8182b0cdb841","placeholder":"​","style":"IPY_MODEL_51cf4efbc83449eabade4a3b7df076ba","value":"Downloading: 100%"}},"2432a9c063bd4c768e63fa92e83f3295":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26dc86bff89f401283a8892d8cbdf32c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c64d70ff2234b61a20cc5d78164cea2","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e283fe994de848cea24badddef7fd8e5","value":873673253}},"27fd64599f4c4a098ae46dfa2d2fb82d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2848e872d76047fb9cbebf16603499dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46f893a4968a4da6a307872a0dbd6d8f","IPY_MODEL_c775b802a97b43df9b352b972201fa85","IPY_MODEL_ac398d0c29ed4ac4add6a15a5435e7d8"],"layout":"IPY_MODEL_b5f8699371124e328cf7f11690ce568f"}},"2932017ba81146dc9f42864b2fb503aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c64d70ff2234b61a20cc5d78164cea2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3505136ed29b45338bdac035ba6efc44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3793d6ee547d445981003e4864bc650b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416e08e6975643c4906c54e9441d0e2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f893a4968a4da6a307872a0dbd6d8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e3d5325295141b9af5c9224106c3810","placeholder":"​","style":"IPY_MODEL_2432a9c063bd4c768e63fa92e83f3295","value":"Downloading: 100%"}},"4ede8edce45541eeb6867b40b9d8f111":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a393db465c6e499b9b3ed64247d8ab64","placeholder":"​","style":"IPY_MODEL_125b4cee2b744e95abbb42e4a628b417","value":" 833M/833M [00:14\u0026lt;00:00, 61.7MB/s]"}},"51cf4efbc83449eabade4a3b7df076ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58f6a93d36fa4b4fbdf3ac2f9017ca82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f2c072ef6424ef38a7fe76385a6a69f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a8fab6d6b0d4b73a78e564db1a839c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0abfd07a0c42cfacbb6f5adacdf201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3793d6ee547d445981003e4864bc650b","placeholder":"​","style":"IPY_MODEL_a383e91e261844efbcfa097c02471dff","value":" 52.0/52.0 [00:00\u0026lt;00:00, 1.76kB/s]"}},"7fe1993fff434267a3c473d4d7c50ccb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e64b78c23b499abf76a91d62633804":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d44fc2eac8584f56bf2db0e8a9ba7f6f","IPY_MODEL_baf6b792b92b4b819126ebfc776dc1ad","IPY_MODEL_aa4e28c22fbb419fbed1d6659f559c1a"],"layout":"IPY_MODEL_27fd64599f4c4a098ae46dfa2d2fb82d"}},"852dc6d194b84ae788e9f75384ca2f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"861808a2dbed4b78babb8182b0cdb841":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89abceb924dc4d72aa846d2e6cdfe1c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1a7e169e994da6b18a77ef875bbf4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e3d5325295141b9af5c9224106c3810":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a1fedd86234c77a50666903b5aa6dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fe1993fff434267a3c473d4d7c50ccb","placeholder":"​","style":"IPY_MODEL_8b1a7e169e994da6b18a77ef875bbf4c","value":"  1%"}},"a383e91e261844efbcfa097c02471dff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a393db465c6e499b9b3ed64247d8ab64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa4e28c22fbb419fbed1d6659f559c1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e851a496a2224303bca00a1300d43d79","placeholder":"​","style":"IPY_MODEL_f0acea016f5e45e594d05244512a9666","value":" 580/580 [00:00\u0026lt;00:00, 21.1kB/s]"}},"ac398d0c29ed4ac4add6a15a5435e7d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_004bda8732f348b59e58e5755c153c2f","placeholder":"​","style":"IPY_MODEL_d4b5701604b04e559d78194121a9ab14","value":" 2.35M/2.35M [00:00\u0026lt;00:00, 9.56MB/s]"}},"b5f8699371124e328cf7f11690ce568f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf6b792b92b4b819126ebfc776dc1ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89abceb924dc4d72aa846d2e6cdfe1c8","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05098bd3c8e148aea403a30221888f0c","value":580}},"c6cbe18f52264f37a914c7abf3e923f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f49877d4f147b39cff816da9694d6e","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58f6a93d36fa4b4fbdf3ac2f9017ca82","value":52}},"c775b802a97b43df9b352b972201fa85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceef8840efe8452aabaed06ffc6d5064","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_852dc6d194b84ae788e9f75384ca2f46","value":2464616}},"c8d085e76d3d4db289f45439f71b5940":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3505136ed29b45338bdac035ba6efc44","placeholder":"​","style":"IPY_MODEL_127deb6965054d3eaf250db46354a9d4","value":" 12/1842 [00:22\u0026lt;46:53,  1.54s/it, loss=1.66, lr=8e-7]"}},"ceef8840efe8452aabaed06ffc6d5064":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d44fc2eac8584f56bf2db0e8a9ba7f6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aec48847b5f4aa7aadc2f098567efc0","placeholder":"​","style":"IPY_MODEL_2932017ba81146dc9f42864b2fb503aa","value":"Downloading: 100%"}},"d4b5701604b04e559d78194121a9ab14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d90660e5ea3b49a5bb060c6afbe8d5d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dfd43845ba84b759deba6c1f12e13c2","placeholder":"​","style":"IPY_MODEL_1bfc703f02e043cea80313d15c76574e","value":"Downloading: 100%"}},"da15c43d200740cab0c89a713232d0b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e283fe994de848cea24badddef7fd8e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e482a79f9f7a45e8a7e0f38e298da840":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_416e08e6975643c4906c54e9441d0e2a","max":1842,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f2c072ef6424ef38a7fe76385a6a69f","value":12}},"e7f49877d4f147b39cff816da9694d6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e851a496a2224303bca00a1300d43d79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e85cbc98fb8d4ecdbd1dd234a0a0ab6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d90660e5ea3b49a5bb060c6afbe8d5d9","IPY_MODEL_26dc86bff89f401283a8892d8cbdf32c","IPY_MODEL_4ede8edce45541eeb6867b40b9d8f111"],"layout":"IPY_MODEL_da15c43d200740cab0c89a713232d0b4"}},"f0acea016f5e45e594d05244512a9666":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f783643d9ee3492baa3dd45e577fd19b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}