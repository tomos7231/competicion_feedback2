{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1658812811764,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"529671eb-d831-4289-9def-1fbb0b3fc844"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jul 26 05:20:11 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback-Exp015-mlm-essay-deberta-large\"\n","    MODEL_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback/wanwan7123/Output/feedback-mlm-deberta-large/model/checkpoint-7000\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-effectiveness\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 4\n","    n_epochs = 5\n","    \n","    fc_dropout = 0.1\n","    weight_decay = 0.001\n","    beta = (0.9, 0.98)\n","    lr = 5e-6\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"fp16\": True,\n","        \"freezing\": True,\n","        \"optim8bit\": True,\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99797,"status":"ok","timestamp":1658813143954,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"a5e8caae-60f8-4198-aab3-d42183a57cf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.10\n","  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:42tcmalloc: large alloc 1147494400 bytes == 0x65e82000 @  0x7f12966cf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.0\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import log_loss\n","!pip install torch==1.10\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    train['fold'] = fold_series\n","    return train, fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collator:\n","    def __init__(self, tokenizer, input_cols, meta_cols=None):\n","        self.tokenizer = tokenizer\n","        self.input_cols = input_cols\n","        \n","        self.meta_cols = meta_cols if meta_cols is not None else []\n","        \n","        self.padding = True\n","        self.max_length: Optional[int] = None\n","        self.pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        first = features[0]\n","        \n","        input_features = []\n","        meta_features = {meta_col:[] for meta_col in self.meta_cols}\n","        \n","        for f in features:\n","            input_features.append({col:f[col] for col in self.input_cols})\n","            for meta_col in self.meta_cols:\n","                meta_features[meta_col].extend(f[meta_col])\n","            \n","        batch = self.tokenizer.pad(\n","            input_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","        \n","        if \"label\" in first:\n","            batch[\"labels\"] = pad_sequence([torch.tensor(f[\"label\"], dtype=torch.long) for f in features], batch_first=True, padding_value=-1)\n","\n","        if \"seq_ids\" in first:\n","            batch[\"seq_ids\"] = pad_sequence([torch.tensor(f[\"seq_ids\"], dtype=torch.long) for f in features], batch_first=True, padding_value=-1)\n","            \n","        if self.meta_cols is not None:\n","            batch[\"meta\"] = meta_features\n","\n","        \n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3571,"status":"ok","timestamp":1658813174049,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"oPz3nkpUvn9s","outputId":"c081fc33-c236-4979-8591-585037af026b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\r\u001b[K     |                                | 10 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |▏                               | 20 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |▎                               | 30 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 51 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 61 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |▊                               | 71 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 81 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 92 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 102 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 112 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 122 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 133 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 143 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 153 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 163 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 174 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 184 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 194 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 204 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 215 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 225 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 235 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 245 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 256 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 266 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 276 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 286 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 296 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 307 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 317 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 327 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 337 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 348 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 358 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 368 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 378 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 389 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 399 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 409 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 419 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 430 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 440 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 450 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 460 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 471 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 481 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 491 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 501 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 512 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 522 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 532 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 542 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 552 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 563 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 573 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 583 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 593 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 604 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 614 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 624 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 634 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 645 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 655 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 665 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 675 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 686 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 696 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 706 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 716 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 727 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 737 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 747 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 757 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 768 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 778 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 788 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 798 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 808 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 819 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 829 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 839 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 849 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 860 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 870 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 880 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 890 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 901 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 911 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 921 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 931 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 942 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 952 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 962 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 972 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 983 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 993 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.4 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.5 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.6 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.7 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.8 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.9 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.1 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.2 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3 MB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3 MB 14.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q bitsandbytes-cuda110"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZabItR15TO6B"},"outputs":[],"source":["# 勾配計算をしない\n","import bitsandbytes as bnb\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0EEPotHB-SJ"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["def flatten(_list):\n","    return list(itertools.chain.from_iterable(_list))\n","\n","def even_split(input_ids):\n","    best_idx = None\n","    best_len = 100000\n","    for i in range(1, len(input_ids)):\n","        x_len = len(flatten(input_ids[:i]))\n","        y_len = len(flatten(input_ids[i:]))\n","        diff = abs(x_len - y_len)\n","        \n","        if best_len > diff:\n","            best_len = diff\n","            best_idx = i\n","    \n","    return best_idx\n","\n","def preprocess_df(df, tokenizer, max_length=198, total_max_length:int=1024):\n","    df['discourse_text'] = df['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    df[\"input_text\"] = df[\"discourse_type\"] + \" \" + df[\"discourse_text\"]\n","    \n","    gdf = df.groupby(\"essay_id\")\n","    fold_df = df.groupby('essay_id')['fold'].apply(lambda x: list(x)[0])\n","    \n","    essay_inputs = df.groupby(\"essay_id\")[\"input_text\"].apply(list)\n","    essay_ids = essay_inputs.index.tolist()\n","    \n","    labels = gdf[\"label\"].apply(list)\n","    discourse_ids = gdf[\"discourse_id\"].apply(list)\n","    \n","    rows = []\n","    for i in tqdm(range(len(essay_inputs))):\n","        # まず全体をtokenizeして1024に収まっていれば、各テキストをtruncationしておく必要はない\n","        input_ids = tokenizer.batch_encode_plus(essay_inputs[i], max_length=total_max_length, truncation=True)[\"input_ids\"]\n","        \n","        if len(flatten(input_ids)) > total_max_length:\n","            split_idx = even_split(input_ids)\n","            \n","            first = input_ids[:split_idx]\n","            first_seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(first)]\n","\n","            second = input_ids[split_idx:]\n","            second_seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(second)]\n","            essay_id = essay_ids[i]\n","            \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":1,\n","                \"discourse_id\": discourse_ids[i][:split_idx ],\n","                \"label\":labels[i][:split_idx],\n","                \"input_ids\":flatten(first),\n","                \"seq_ids\":flatten(first_seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","        \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":2,\n","                \"discourse_id\": discourse_ids[i][split_idx:],\n","                \"label\":labels[i][split_idx:],\n","                \"input_ids\":flatten(second),\n","                \"seq_ids\":flatten(second_seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","        else:\n","            # もしかしたら一つのtextで1024超える場合もある？\n","            seq_ids = [[seq_ids]*len(ids) for seq_ids, ids in enumerate(input_ids)]\n","            input_ids = flatten(input_ids)\n","            essay_id = essay_ids[i]\n","            \n","            rows.append({\n","                \"essay_id\":essay_ids[i],\n","                \"group\":1,\n","                \"discourse_id\": discourse_ids[i],\n","                \"label\":labels[i],\n","                \"input_ids\":input_ids,\n","                \"seq_ids\":flatten(seq_ids),\n","                \"fold\":fold_df[essay_id],\n","            })\n","            \n","    return pd.DataFrame(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53jHZmig2OH2"},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer):\n","        super().__init__()\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        \n","        inputs = {}\n","        \n","        input_ids = np.array(row[\"input_ids\"])\n","        seq_ids = np.array(row[\"seq_ids\"])\n","        \n","        label = np.full(len(input_ids), -1, dtype=np.int64)\n","        label[np.argwhere(input_ids==self.tokenizer.cls_token_id).reshape(-1)] = row[\"label\"]\n","        \n","        attention_mask = np.array([1 if id != self.tokenizer.pad_token_id else 0 for id in input_ids], dtype=np.int64)\n","        \n","        inputs = {\n","            \"discourse_id\":row[\"discourse_id\"],\n","            \"input_ids\":input_ids,\n","            \"attention_mask\":attention_mask,\n","            \"seq_ids\":seq_ids,\n","            \"label\":label,\n","        }\n","        \n","        return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDh1Mz2G2Cnm"},"outputs":[],"source":["class SimpleHeader(nn.Module):\n","    def __init__(self, input_size:int, num_labels):\n","        super().__init__()\n","        self.fc = nn.Linear(input_size, num_labels)\n","\n","        self.cls_dropouts = nn.Sequential(\n","            nn.Dropout(0.1),\n","            nn.Dropout(0.2),\n","            nn.Dropout(0.3),\n","            nn.Dropout(0.4),\n","            nn.Dropout(0.5),\n","        )\n","\n","    def forward(self, x):\n","        output = torch.mean(\n","            torch.stack(\n","                [self.fc(self.cls_dropouts[i](x)) for i in range(5)],\n","                dim=0,\n","            ),\n","            dim=0,\n","        )\n","        return output\n","\n","class LitModel(nn.Module):\n","    def __init__(self,cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": 0.1,\n","                \"layer_norm_eps\": 1e-7,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": 3,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )   \n","        self.hidden_size = self.config.hidden_size\n","        self.fc = nn.Linear(self.config.hidden_size, 3)\n","        self.header = SimpleHeader(input_size=self.config.hidden_size, num_labels=3)\n","        self._init_weights(self.header.fc)\n","\n","        # Freeze\n","        if self.gpu_optimize_config['freezing']:\n","            freeze(self.backbone.embeddings)\n","            freeze(self.backbone.encoder.layer[:2])\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()\n","\n","    @property\n","    def device(self):\n","        return self.backbone.device\n","            \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    # トークンごとに平均取って潰す\n","    def sequence_mean(self, logits, batch):\n","        batch_seq_mean = []\n","        batch_size = batch[\"input_ids\"].shape[0]\n","        seq_lens = []\n","        # バッチサイズごとに\n","        for i in range(batch_size):\n","            seq_mean = []\n","            # バッチの長さに応じて処理\n","            # iはバッチを表すので、そのバッチで何個文章がくっついてるかをjは表す\n","            for j in range(max(batch[\"seq_ids\"][i])+1):\n","                # i, j成分（該当するdiscourse）を取り出す\n","                idx = batch[\"seq_ids\"][i]==j\n","                idx = idx.nonzero().reshape(-1)\n","                # idxでtensorの抜き出しを行う\n","                seq_tensor = torch.index_select(logits[i], 0, idx)\n","                # tokenごと潰してseq_meanに追加\n","                seq_mean.append(seq_tensor.mean(axis=0))\n","\n","            seq_lens.append(len(seq_mean))\n","            batch_seq_mean.append(torch.vstack(seq_mean))\n","\n","        return batch_seq_mean, seq_lens\n","            \n","    def forward(self, input_dict):\n","        # batch, len, hidden_size\n","        output = self.backbone(\n","            input_ids=input_dict[\"input_ids\"],\n","            attention_mask=input_dict[\"attention_mask\"]\n","        )[\"last_hidden_state\"]\n","    \n","        # discourse, hidden_size\n","        output, seq_lens = self.sequence_mean(output, input_dict)\n","        # discourse, hidden_size\n","        output = torch.vstack(output)\n","        output = self.header(output)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPeBFK41drE5"},"outputs":[],"source":["def get_optimizer_grouped_parameters(model):\n","    model_type = 'backbone'\n","    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": cfg.lr,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n","    layers.reverse()\n","    lr = cfg.lr\n","    for layer in layers:\n","        lr *= 0.98\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_all_df = pd.DataFrame()\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[train['fold']!=fold]\n","        valid_df = train.loc[train['fold']==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(train_df, cfg.tokenizer)\n","        valid_dataset = TrainDataset(valid_df, cfg.tokenizer)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collator(cfg.tokenizer, input_cols = [\"input_ids\", \"attention_mask\"], meta_cols = [\"discourse_id\"])\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collator(cfg.tokenizer, input_cols = [\"input_ids\", \"attention_mask\"], meta_cols = [\"discourse_id\"])\n","        )\n","\n","        # model\n","        model = LitModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        optimizer_grouped_parameters = get_optimizer_grouped_parameters(model)\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        \n","        if cfg.gpu_optimize_config['gradient_checkpoint']:\n","            optimizer = bnb.optim.AdamW(optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","            optim_bits=8)\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.CrossEntropyLoss()\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            val_losses_batch = []\n","            ids = []\n","            scaler = GradScaler()\n","            # dataloader回して予測\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs) in enumerate(pbar):\n","\n","                    meta = inputs.pop(\"meta\", None)\n","                    inputs = {k:v.to(cfg.device) for k, v in inputs.items()}\n","\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        output = model(inputs)\n","                    ids.extend(meta[\"discourse_id\"])\n","\n","                    labels = inputs['labels'][torch.where(inputs['labels'] != -1)]\n","                    loss = criterion(output, labels)\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps > 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating\n","            val_preds = []\n","            val_losses = []\n","            val_nums = []\n","            ids = []\n","            model.eval()\n","            with torch.no_grad():\n","                with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","                    for steps, (inputs) in enumerate(pbar):\n","\n","                        meta = inputs.pop(\"meta\", None)\n","                        inputs = {k:v.to(cfg.device) for k, v in inputs.items()}\n","\n","                        with autocast():\n","                            output = model(inputs)\n","                        ids.extend(meta[\"discourse_id\"])\n","\n","                        labels = inputs['labels'][torch.where(inputs['labels'] != -1)]\n","                        loss = criterion(output, labels.to(torch.long))\n","\n","                        output = output.detach().cpu().numpy()\n","                        val_preds.append(output)\n","                        val_losses.append(loss.item() * len(labels))\n","                        val_nums.append(len(labels))\n","                        pbar.set_postfix({\n","                            'val_loss': loss.item()\n","                        })\n","\n","            val_preds = np.vstack(val_preds)\n","            val_loss = sum(val_losses) / sum(val_nums)\n","\n","            val_log = {\n","                'val_loss': val_loss\n","            }\n","            display(val_log)\n","\n","            if best_val_score > val_loss:\n","                print(\"save model weight\")\n","                best_val_preds = val_preds\n","                best_val_score = val_loss\n","                torch.save(\n","                    model.state_dict(), \n","                    os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","                )\n","        oof_df = pd.DataFrame(ids, columns=['discourse_id'])\n","        oof_df['Ineffective'] = best_val_preds[:, 0]\n","        oof_df['Adequate'] = best_val_preds[:, 1]\n","        oof_df['Effective'] = best_val_preds[:, 2]\n","        oof_df.to_csv(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.csv'))\n","        oof_all_df = pd.concat([oof_all_df, oof_df], axis=0)\n","        del model; gc.collect()\n","\n","    oof_all_df.to_csv(os.path.join(cfg.EXP_PREDS, 'oof_pred.csv'))\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    '''\n","    metric = nn.CrossEntropyLoss()\n","    score = metric(torch.from_numpy(oof_pred), torch.from_numpy(train['label'].values))\n","    print('CV:', score.to('cpu').detach().numpy())\n","    '''\n","    return oof_all_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["63c3be5e0f6f46e1a0b16dfa73dc80a1","6d6910173299462b9b6b9a8521d06eac","91ca4cc1657f4afda9fdb123403cc29f","9bf38b12996347e293ff0e773b1580c0","737419d9df42461dabfffe5ef6b2cfb0","a336ed07858b46d099b4b4d23c449e68","6d6a71b397194a96b96c070d9f3c9117","d8e6c824ee8a45fe8fc89ce18c666ec4","e0b311c7db594978a73d8de12587b66e","043befd3b0a14c9ab51ea6af9a1a50c4","8c4ad9e0cc6a45aa93b1bdaee697e69d","dd1f16102ef14fffb723ee7062f8111e","3350cbb4bda64a92997722c3e9948b90","f2ceb5f6b1d7421e85829518e0fd228c","5a0e9b8500764d35b19e61762c8b0810","d840001fe3eb48db8bcc652703dbc930","9af62fef6f384371aaed959de617318f","42509e398b074afeb1ea961aa3dd11d3","58efbe65f90b45b7a1b10397bebb3b1c","eff187af15dd438a941512e42b200945","ed4bd4a8122d4bcb804ef22f855262fd","c191870dde934af8bf18c9cf23b8a2aa","fe9325f03d894ac69d7a54442919b476","db10acdd2d794274872ec30cbf1d9a25","1c93cafa081247f0a2f6873f0209be8b","f7240f3ee9cb4b3ab3681c12f28bc9b2","4e06f2dcc5e84fadbc1676358cc4537a","7a9d087002de44f9849f5863376e8a23","9017be3f57c8448da1bf70f2d63de3d0","fb8541359a4941589a7b3996ff0e134c","9c3e52de0a294c8a930b949d2ca7d713","b09162cd4e0c46c4be6c7d2cc83f95ad","9956927028ed4306ba4a941e381b138e","3cc149aa1e604101b7a5eb356827c356","4eaab4f729cd4160bd2e6d35d7631a5c","1d8165c922094fb08da7db2a3d57cc12","388e7dbbb2be494d832357fe4874a9b9","3597b1e6cd02417fba45d7f2608b1141","a4825c4508ff49a09407efe0dcd3cfc7","f12b2ed50efc4bffbe5fc6c8390f6263","d8daf55d2cd74ec0ad85e448576f2c51","0c11729fff814deea0d4ceeeb6525638","e6760f6ef2c742ff81a1af7ac933aa5e","38a58f81c18f4cbfbc47f5885441488c","d43ad4de475b47e3ac9a97bf2da0bd26","9b8c51f00f1f40b080dad545698dcee9","7b608eea2a164cadbd0a3b42afa04631","5b23ee7661ef474d900daff356bf3b81","565d31cd2c6c49998729d16cd8f15553","777d7c4939ad45c080e62739271feceb","af83db909a1944b7b3be2b2b4c299dd4","006f482d7c0e4a81a2454871c38483b0","a42199d868b348e8867ec3ce42945a2c","2e64fcfbbf1649c48770e6c1e4de431a","70cb18e328d84bbda5c89cf834e43762","dcb14eab6a184c399076604d95a12fcc","99673caa2dcb4c9e9bacac719bff523f","9d5f5527580c4c9ea921d9a6d213248a","4371208add1f4ca0bc8a02ebc379eca9","6ef9f05c5a694accb8d87506b4bb05e7","68df7864a85f465298c20fe7519629f6","ead43922ced541c39f9d1c4ff7e05a1c","e553be4df37a440b8df33f8bb8cd97df","8fb48e5f8e554549867ebca8fec1bf64","0b01c2b2e00343e2be66463ab622993c","77f547e1d93d4002bc69313910bbaac6","de5564c7590641a09a61763227d3c6e3","5fa4941550e34417b827d8666976a57b","adda23a34f934435af4f5c7a10cbc638","504ece174ad04355b27e22addf9d2b99","1344fc423203470ba3bc5cf51c3f3c54","d02a6248b4c64a2ea54e14a14b2a092f","32a29a6b20e24e8b86fae54627b04324","bff84917e47e44e780d86101d92a33f9","634ac7fa8bd947f4a85bda39a2882d4b","abc88f5bc692492b97f6cb6f01bf5371","4116e0e0f0b04076901103308b47e697","5b55cde0fd59458da7d79becd00cec62","d19b23e5f0db43c3889690ffcaba4e55","3a48e00872314a7ba5001e7f55febaa9","6860f1dedf51459892819619652712ed","319122fdba4441709a6c17253d30953b","70b84bf4eaff4f1b9ddfd3dfcd14a398","ef97a4c12b63494bbe2498ba6e384227","6014605b8e6442f796663d2cc7297c91","11cc5c18a7db460d84c556fe281f0635","5a2a91f5c017404e93f2f02958c70ac2","3cde45419e98442e98496508a3f4e8dd","28bc029c0ec042709efdddf3bc4a538b","bb4aa69b4b6e4e75975b6dde4f1526ed","c8d397e5ab4c4b1ca09704d45c1e41e9","acc073a496094ac9a95ab03b45406afb","e5c5587f406f4be5949b2921ccec188d"]},"id":"gSrrvDWVpxN_","outputId":"dac3d15d-5320-4154-fb1e-4b068d28769b"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 13.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 73.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 79.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f53432bb7cdb2eabbf8535dac7e6148a2e26c63d0fcdb5f1694c6979e56bd80d\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.16.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.11.6\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 15.0 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","Successfully installed tokenizers-0.11.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.8.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Collecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 14.3 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63c3be5e0f6f46e1a0b16dfa73dc80a1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4191 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd1f16102ef14fffb723ee7062f8111e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe9325f03d894ac69d7a54442919b476","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cc149aa1e604101b7a5eb356827c356","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7367472118010175}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43ad4de475b47e3ac9a97bf2da0bd26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6502187242551146}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b8c51f00f1f40b080dad545698dcee9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.6240294548171426}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b608eea2a164cadbd0a3b42afa04631","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6319618628409052}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b23ee7661ef474d900daff356bf3b81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.554425683885578}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"565d31cd2c6c49998729d16cd8f15553","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6781479860258908}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"777d7c4939ad45c080e62739271feceb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.49443879022430864}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af83db909a1944b7b3be2b2b4c299dd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6318826587681716}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"006f482d7c0e4a81a2454871c38483b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4469049024180335}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a42199d868b348e8867ec3ce42945a2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6590984762983467}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e64fcfbbf1649c48770e6c1e4de431a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/880 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7352753122997403}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70cb18e328d84bbda5c89cf834e43762","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/214 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6599088530180399}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcb14eab6a184c399076604d95a12fcc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/880 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.6222188171106816}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99673caa2dcb4c9e9bacac719bff523f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/214 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6373447329373787}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d5f5527580c4c9ea921d9a6d213248a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/880 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5586151075713657}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4371208add1f4ca0bc8a02ebc379eca9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/214 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6370336582396513}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ef9f05c5a694accb8d87506b4bb05e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/880 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4959919355369941}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68df7864a85f465298c20fe7519629f6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/214 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6498153783438824}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ead43922ced541c39f9d1c4ff7e05a1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/880 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4503264844921862}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e553be4df37a440b8df33f8bb8cd97df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/214 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6779565244471429}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fb48e5f8e554549867ebca8fec1bf64","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/874 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7414047134506119}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b01c2b2e00343e2be66463ab622993c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6612432076853247}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f547e1d93d4002bc69313910bbaac6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/874 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.6269911803142817}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de5564c7590641a09a61763227d3c6e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6281009673026857}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fa4941550e34417b827d8666976a57b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/874 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5653160102468104}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adda23a34f934435af4f5c7a10cbc638","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6382247075932619}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"504ece174ad04355b27e22addf9d2b99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/874 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.511448360279421}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1344fc423203470ba3bc5cf51c3f3c54","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6480405122229549}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d02a6248b4c64a2ea54e14a14b2a092f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/874 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.46889318479655034}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32a29a6b20e24e8b86fae54627b04324","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6356041600652576}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bff84917e47e44e780d86101d92a33f9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/870 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7540089071533028}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"634ac7fa8bd947f4a85bda39a2882d4b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/224 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6954562839628755}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abc88f5bc692492b97f6cb6f01bf5371","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/870 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.6382617311090137}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4116e0e0f0b04076901103308b47e697","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/224 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.603071809670799}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b55cde0fd59458da7d79becd00cec62","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/870 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5752511782286357}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d19b23e5f0db43c3889690ffcaba4e55","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/224 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.5956617749393446}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a48e00872314a7ba5001e7f55febaa9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/870 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5172297475601805}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6860f1dedf51459892819619652712ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/224 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6032243245334519}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"319122fdba4441709a6c17253d30953b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/870 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4685773168990409}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70b84bf4eaff4f1b9ddfd3dfcd14a398","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/224 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.617934527469423}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef97a4c12b63494bbe2498ba6e384227","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.7319666917509978}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6014605b8e6442f796663d2cc7297c91","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6701056007283556}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11cc5c18a7db460d84c556fe281f0635","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.6189919432924597}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a2a91f5c017404e93f2f02958c70ac2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6745137938003167}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cde45419e98442e98496508a3f4e8dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.5517258604242326}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28bc029c0ec042709efdddf3bc4a538b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6744728083344331}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb4aa69b4b6e4e75975b6dde4f1526ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.496043981714446}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8d397e5ab4c4b1ca09704d45c1e41e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6707551333651594}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acc073a496094ac9a95ab03b45406afb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/875 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.4500849649189628}"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5c5587f406f4be5949b2921ccec188d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.6835296457670005}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7.55G/7.55G [03:42<00:00, 36.4MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (8GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:01<00:00, 5.46kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.91M/2.91M [00:02<00:00, 1.43MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (3MB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3.22M/3.22M [00:02<00:00, 1.34MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (3MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36k/2.36k [00:01<00:00, 1.29kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (2KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_full.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback/wanwan7123/Output/feedback-mlm-deberta-large/tokenizer')\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","train['label'] = train['discourse_effectiveness'].map({'Ineffective':0, 'Adequate':1, 'Effective':2})\n","train, cfg.folds = get_groupstratifiedkfold(train, 'label', 'essay_id', cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","\n","train = preprocess_df(train, cfg.tokenizer, max_length=198, total_max_length=1024)\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"exp015_essay.ipynb","provenance":[],"mount_file_id":"1futN_1h78QVygchqC8qrmUG11RKkIlQU","authorship_tag":"ABX9TyN1KG2L3XxQAC4fnjFx+0RT"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"043befd3b0a14c9ab51ea6af9a1a50c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c11729fff814deea0d4ceeeb6525638":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c93cafa081247f0a2f6873f0209be8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb8541359a4941589a7b3996ff0e134c","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c3e52de0a294c8a930b949d2ca7d713","value":1627284589}},"1d8165c922094fb08da7db2a3d57cc12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8daf55d2cd74ec0ad85e448576f2c51","max":875,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c11729fff814deea0d4ceeeb6525638","value":3}},"3350cbb4bda64a92997722c3e9948b90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af62fef6f384371aaed959de617318f","placeholder":"​","style":"IPY_MODEL_42509e398b074afeb1ea961aa3dd11d3","value":"Downloading: 100%"}},"3597b1e6cd02417fba45d7f2608b1141":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388e7dbbb2be494d832357fe4874a9b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6760f6ef2c742ff81a1af7ac933aa5e","placeholder":"​","style":"IPY_MODEL_38a58f81c18f4cbfbc47f5885441488c","value":" 3/875 [00:14&lt;1:23:08,  5.72s/it, loss=1, lr=2.33e-7]"}},"38a58f81c18f4cbfbc47f5885441488c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cc149aa1e604101b7a5eb356827c356":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4eaab4f729cd4160bd2e6d35d7631a5c","IPY_MODEL_1d8165c922094fb08da7db2a3d57cc12","IPY_MODEL_388e7dbbb2be494d832357fe4874a9b9"],"layout":"IPY_MODEL_3597b1e6cd02417fba45d7f2608b1141"}},"42509e398b074afeb1ea961aa3dd11d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e06f2dcc5e84fadbc1676358cc4537a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eaab4f729cd4160bd2e6d35d7631a5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4825c4508ff49a09407efe0dcd3cfc7","placeholder":"​","style":"IPY_MODEL_f12b2ed50efc4bffbe5fc6c8390f6263","value":"  0%"}},"58efbe65f90b45b7a1b10397bebb3b1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0e9b8500764d35b19e61762c8b0810":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed4bd4a8122d4bcb804ef22f855262fd","placeholder":"​","style":"IPY_MODEL_c191870dde934af8bf18c9cf23b8a2aa","value":" 475/475 [00:00&lt;00:00, 18.7kB/s]"}},"63c3be5e0f6f46e1a0b16dfa73dc80a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d6910173299462b9b6b9a8521d06eac","IPY_MODEL_91ca4cc1657f4afda9fdb123403cc29f","IPY_MODEL_9bf38b12996347e293ff0e773b1580c0"],"layout":"IPY_MODEL_737419d9df42461dabfffe5ef6b2cfb0"}},"6d6910173299462b9b6b9a8521d06eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a336ed07858b46d099b4b4d23c449e68","placeholder":"​","style":"IPY_MODEL_6d6a71b397194a96b96c070d9f3c9117","value":"100%"}},"6d6a71b397194a96b96c070d9f3c9117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"737419d9df42461dabfffe5ef6b2cfb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a9d087002de44f9849f5863376e8a23":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c4ad9e0cc6a45aa93b1bdaee697e69d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9017be3f57c8448da1bf70f2d63de3d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91ca4cc1657f4afda9fdb123403cc29f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8e6c824ee8a45fe8fc89ce18c666ec4","max":4191,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0b311c7db594978a73d8de12587b66e","value":4191}},"9956927028ed4306ba4a941e381b138e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9af62fef6f384371aaed959de617318f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bf38b12996347e293ff0e773b1580c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_043befd3b0a14c9ab51ea6af9a1a50c4","placeholder":"​","style":"IPY_MODEL_8c4ad9e0cc6a45aa93b1bdaee697e69d","value":" 4191/4191 [00:06&lt;00:00, 693.59it/s]"}},"9c3e52de0a294c8a930b949d2ca7d713":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a336ed07858b46d099b4b4d23c449e68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4825c4508ff49a09407efe0dcd3cfc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b09162cd4e0c46c4be6c7d2cc83f95ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c191870dde934af8bf18c9cf23b8a2aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d840001fe3eb48db8bcc652703dbc930":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8daf55d2cd74ec0ad85e448576f2c51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8e6c824ee8a45fe8fc89ce18c666ec4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db10acdd2d794274872ec30cbf1d9a25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a9d087002de44f9849f5863376e8a23","placeholder":"​","style":"IPY_MODEL_9017be3f57c8448da1bf70f2d63de3d0","value":"Downloading: 100%"}},"dd1f16102ef14fffb723ee7062f8111e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3350cbb4bda64a92997722c3e9948b90","IPY_MODEL_f2ceb5f6b1d7421e85829518e0fd228c","IPY_MODEL_5a0e9b8500764d35b19e61762c8b0810"],"layout":"IPY_MODEL_d840001fe3eb48db8bcc652703dbc930"}},"e0b311c7db594978a73d8de12587b66e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6760f6ef2c742ff81a1af7ac933aa5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed4bd4a8122d4bcb804ef22f855262fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eff187af15dd438a941512e42b200945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f12b2ed50efc4bffbe5fc6c8390f6263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2ceb5f6b1d7421e85829518e0fd228c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58efbe65f90b45b7a1b10397bebb3b1c","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eff187af15dd438a941512e42b200945","value":475}},"f7240f3ee9cb4b3ab3681c12f28bc9b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09162cd4e0c46c4be6c7d2cc83f95ad","placeholder":"​","style":"IPY_MODEL_9956927028ed4306ba4a941e381b138e","value":" 1.52G/1.52G [00:25&lt;00:00, 64.5MB/s]"}},"fb8541359a4941589a7b3996ff0e134c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe9325f03d894ac69d7a54442919b476":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db10acdd2d794274872ec30cbf1d9a25","IPY_MODEL_1c93cafa081247f0a2f6873f0209be8b","IPY_MODEL_f7240f3ee9cb4b3ab3681c12f28bc9b2"],"layout":"IPY_MODEL_4e06f2dcc5e84fadbc1676358cc4537a"}}}}},"nbformat":4,"nbformat_minor":0}